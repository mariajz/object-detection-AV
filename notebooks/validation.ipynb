{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"validation-ver3","provenance":[{"file_id":"1kbz6CNXdJGzAYYv424rAPdDVcUeoNpZs","timestamp":1619065622010},{"file_id":"1AErgkbNgK7JBWBz4GEGzTCAvvXpsUlwg","timestamp":1618860787549},{"file_id":"1HYIhI_-yeRnl8u7Pno_9BhMwQ5fffMnw","timestamp":1618854305430}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lt1uXfDxIVMV","executionInfo":{"status":"ok","timestamp":1623063435743,"user_tz":-330,"elapsed":688,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"64c67621-2675-4328-cd4e-5e8c30267784"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.environ['CONFIG_DIR'] = \"/content/gdrive/My Drive/Project\"\n","%cd /content/gdrive/My Drive/Project\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/Project\n","\u001b[0m\u001b[01;34mkitti\u001b[0m/  \u001b[01;34moutput\u001b[0m/  readme.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eXXqyQLaIOzW"},"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","from os import listdir\n","from os.path import isfile, join\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import gc; gc.enable() # memory is tight\n","\n","from keras import layers, models\n","from keras import backend as K\n","from keras.optimizers import Adam\n","\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_VyvJgwIOzo"},"source":["# img_dir = 'kitti dataset/'\n","# ../input/kitti_single/training/label_2/\n","train_image_dir_l = 'kitti/training/label_2/'\n","# label_test_image_dir = os.path.join(os.getcwd(), 'streets\\\\test\\\\labels\\\\')\n","\n","train_image_dir = 'kitti/training/image_2/'\n","# test_image_dir = os.path.join(os.getcwd(), 'streets\\\\test\\\\images\\\\')\n","\n","images =  [(train_image_dir+f) for f in listdir(train_image_dir) if isfile(join(train_image_dir, f))]\n","masks = [(train_image_dir_l+f) for f in listdir(train_image_dir_l) if isfile(join(train_image_dir_l, f))]\n","\n","df = pd.DataFrame(np.column_stack([images, masks]), columns=['images', 'masks'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDt65uJaIOzr"},"source":["df1 = df.sort_values(by='images')['images'].reset_index()\n","# df1 = df.sort_values(by='a')['a']\n","df2 = df.sort_values(by='masks')['masks'].reset_index()\n","# df2 = df.sort_values(by='b')['b']\n","df['images'] = df1['images']\n","df['masks'] = df2['masks']\n","del df1, df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"qFrxhx3ln-9w","executionInfo":{"status":"ok","timestamp":1623063442449,"user_tz":-330,"elapsed":39,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"5273555d-9fe5-4db4-bc13-b940cff3c761"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>images</th>\n","      <th>masks</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>kitti/training/image_2/000000.png</td>\n","      <td>kitti/training/label_2/000000.txt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>kitti/training/image_2/000001.png</td>\n","      <td>kitti/training/label_2/000001.txt</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>kitti/training/image_2/000002.png</td>\n","      <td>kitti/training/label_2/000002.txt</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>kitti/training/image_2/000003.png</td>\n","      <td>kitti/training/label_2/000003.txt</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>kitti/training/image_2/000004.png</td>\n","      <td>kitti/training/label_2/000004.txt</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7476</th>\n","      <td>kitti/training/image_2/007476.png</td>\n","      <td>kitti/training/label_2/007476.txt</td>\n","    </tr>\n","    <tr>\n","      <th>7477</th>\n","      <td>kitti/training/image_2/007477.png</td>\n","      <td>kitti/training/label_2/007477.txt</td>\n","    </tr>\n","    <tr>\n","      <th>7478</th>\n","      <td>kitti/training/image_2/007478.png</td>\n","      <td>kitti/training/label_2/007478.txt</td>\n","    </tr>\n","    <tr>\n","      <th>7479</th>\n","      <td>kitti/training/image_2/007479.png</td>\n","      <td>kitti/training/label_2/007479.txt</td>\n","    </tr>\n","    <tr>\n","      <th>7480</th>\n","      <td>kitti/training/image_2/007480.png</td>\n","      <td>kitti/training/label_2/007480.txt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7481 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                 images                              masks\n","0     kitti/training/image_2/000000.png  kitti/training/label_2/000000.txt\n","1     kitti/training/image_2/000001.png  kitti/training/label_2/000001.txt\n","2     kitti/training/image_2/000002.png  kitti/training/label_2/000002.txt\n","3     kitti/training/image_2/000003.png  kitti/training/label_2/000003.txt\n","4     kitti/training/image_2/000004.png  kitti/training/label_2/000004.txt\n","...                                 ...                                ...\n","7476  kitti/training/image_2/007476.png  kitti/training/label_2/007476.txt\n","7477  kitti/training/image_2/007477.png  kitti/training/label_2/007477.txt\n","7478  kitti/training/image_2/007478.png  kitti/training/label_2/007478.txt\n","7479  kitti/training/image_2/007479.png  kitti/training/label_2/007479.txt\n","7480  kitti/training/image_2/007480.png  kitti/training/label_2/007480.txt\n","\n","[7481 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"m6h0KRwMI-Yc"},"source":["\n","LABEL_COLORS = {\n","    'Car': (255,0,0), \n","    'Van': (255,255,0), \n","    'Truck': (255,255,255),\n","    'Pedestrian': (0,255,255),\n","    'Person_sitting': (0,255,255), \n","    'Cyclist': (0,128,255), \n","    'Tram': (128,0,0),\n","    'Misc': (0,255,255),\n","    'DontCare': (255,255,0)\n","}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZVk7LGvEIOzs"},"source":["def create_mask_car(mask_dir, img_shape):\n","    mask = np.zeros(shape=(img_shape[0], img_shape[1], 1))\n","\n","    with open(mask_dir) as f:\n","        content = f.readlines()\n","    content = [x.split() for x in content] \n","    for item in content:\n","        if item[0]=='Car' :\n","            ul_col, ul_row = int(float(item[4])), int(float(item[5]))\n","            lr_col, lr_row = int(float(item[6])), int(float(item[7]))\n","            \n","            mask[ul_row:lr_row, ul_col:lr_col, 0] = 1 \n","    return mask\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpXnEr0RkDAL"},"source":["def create_mask_pedestrian(mask_dir, img_shape):\n","    mask = np.zeros(shape=(img_shape[0], img_shape[1], 1))\n","\n","    with open(mask_dir) as f:\n","        content = f.readlines()\n","    content = [x.split() for x in content] \n","    for item in content:\n","        if item[0]=='Car' :\n","            ul_col, ul_row = int(float(item[4])), int(float(item[5]))\n","            lr_col, lr_row = int(float(item[6])), int(float(item[7]))\n","            \n","            mask[ul_row:lr_row, ul_col:lr_col, 0] = 1 \n","    return mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_iyVqQpWxxs"},"source":["def create_mask_van(mask_dir, img_shape):\n","    mask = np.zeros(shape=(img_shape[0], img_shape[1], 1))\n","\n","    with open(mask_dir) as f:\n","        content = f.readlines()\n","    content = [x.split() for x in content] \n","    for item in content:\n","        if item[0]=='Van' :\n","            ul_col, ul_row = int(float(item[4])), int(float(item[5]))\n","            lr_col, lr_row = int(float(item[6])), int(float(item[7]))\n","            \n","            mask[ul_row:lr_row, ul_col:lr_col, 0] = 1 \n","    return mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"as2APlaIIOzs"},"source":["df_train, df_val = train_test_split(df, test_size=0.25, shuffle=False)\n","resized_shape = (160, 256)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BKBgqirIOzt"},"source":["BATCH_SIZE = 64\n","# In[]\n","'''make batchs of images\n","'''\n","def create_images_generator_car(df_in, batch_size, resized_shape):\n","    batch_image_car = []\n","    batch_mask_car = []\n","    df_in_list = (df_in).values.tolist()\n","#     print(len(df_in_list))\n","    np.random.shuffle(df_in_list)\n","    # return df_in_list    \n","    \n","    while True:\n","#         np.random.shuffle(df_in_list)\n","        for image_path, mask_path in df_in_list:\n","            image_r = cv2.imread(image_path)\n","            mask_r = create_mask_car(mask_path, image_r.shape)\n","            \n","            image_r = cv2.resize(image_r,(resized_shape[1], resized_shape[0]))\n","            mask_r = cv2.resize(mask_r,(resized_shape[1], resized_shape[0]))\n","            \n","            \n","            \n","            batch_image_car.append(image_r)\n","            batch_mask_car.append(mask_r)\n","            \n","            if len(batch_mask_car)>=batch_size:\n","                yield np.float32(np.stack((batch_image_car), 0)/255.0), np.stack(np.uint8(np.expand_dims(batch_mask_car, -1)), 0)\n","                batch_image_car, batch_mask_car = [], []\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3evxkaEW3vl"},"source":["def create_images_generator_van(df_in, batch_size, resized_shape):\n","    batch_image_van = []\n","    batch_mask_van = []\n","    df_in_list = (df_in).values.tolist()\n","#     print(len(df_in_list))\n","    np.random.shuffle(df_in_list)\n","    # return df_in_list    \n","    \n","    while True:\n","#         np.random.shuffle(df_in_list)\n","        for image_path, mask_path in df_in_list:\n","            image_r = cv2.imread(image_path)\n","            mask_r = create_mask_car(mask_path, image_r.shape)\n","            \n","            image_r = cv2.resize(image_r,(resized_shape[1], resized_shape[0]))\n","            mask_r = cv2.resize(mask_r,(resized_shape[1], resized_shape[0]))\n","            \n","            \n","            \n","            batch_image_van.append(image_r)\n","            batch_mask_van.append(mask_r)\n","            \n","            if len(batch_mask_van)>=batch_size:\n","                yield np.float32(np.stack((batch_image_van), 0)/255.0), np.stack(np.uint8(np.expand_dims(batch_mask_van, -1)), 0)\n","                batch_image_van, batch_mask_van = [], []\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWzOFJ-sktyB"},"source":["\n","def create_images_generator_pedestrian(df_in, batch_size, resized_shape):\n","    batch_image_pedestrian = []\n","    batch_mask_pedestrian = []\n","    df_in_list = (df_in).values.tolist()\n","#     print(len(df_in_list))\n","    np.random.shuffle(df_in_list)\n","    # return df_in_list    \n","    \n","    while True:\n","#         np.random.shuffle(df_in_list)\n","        for image_path, mask_path in df_in_list:\n","            image_r = cv2.imread(image_path)\n","            mask_r = create_mask_pedestrian(mask_path, image_r.shape)\n","            \n","            image_r = cv2.resize(image_r,(resized_shape[1], resized_shape[0]))\n","            mask_r = cv2.resize(mask_r,(resized_shape[1], resized_shape[0]))\n","            \n","            \n","            \n","            batch_image_pedestrian.append(image_r)\n","            batch_mask_pedestrian.append(mask_r)\n","            \n","            if len(batch_mask_pedestrian)>=batch_size:\n","                yield np.float32(np.stack((batch_image_pedestrian), 0)/255.0), np.stack(np.uint8(np.expand_dims(batch_mask_pedestrian, -1)), 0)\n","                batch_image_pedestrian, batch_mask_pedestrian = [], []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvVHojRaIOzx","scrolled":true},"source":["#train_gen = create_images_generator(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","valid_gen_car = create_images_generator_car(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","val_img_car, val_mask_car = next(valid_gen_car)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfOWKSQjN_pG","executionInfo":{"status":"ok","timestamp":1623063477305,"user_tz":-330,"elapsed":23,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"88bb46e8-fe07-4a47-8f84-0cf7c6f100e8"},"source":["val_img_car.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 160, 256, 3)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXOBEeFqO6T7","executionInfo":{"status":"ok","timestamp":1623063477306,"user_tz":-330,"elapsed":20,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"38a96313-3ef4-4703-c62d-2ae67d76e08a"},"source":["val_mask_car.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64, 160, 256, 1)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Chz3j70OlHL6"},"source":["#train_gen = create_images_generator(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","valid_gen_pedestrian = create_images_generator_pedestrian(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","val_img_pedestrian, val_mask_pedestrian = next(valid_gen_pedestrian)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Rm6akmcXXB-"},"source":["#train_gen = create_images_generator(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","valid_gen_van = create_images_generator_van(df_train, batch_size=BATCH_SIZE, resized_shape=resized_shape)\n","val_img_van, val_mask_van = next(valid_gen_van)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C__3Hew0IfLA","executionInfo":{"status":"ok","timestamp":1623063550521,"user_tz":-330,"elapsed":1357,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"956d3036-4653-4762-f1b2-b1dca2a84f68"},"source":["# load json and create model\n","json_file = open('output/model/model_car.json', 'r',encoding='utf-8-sig')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","from keras.models import model_from_json\n","model_car = model_from_json(loaded_model_json)\n","\n","# load weights into new model\n","model_car.load_weights(\"output/model/model_car.h5\")\n","print(\"Loaded model from disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded model from disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EX1AwDY8oX23","executionInfo":{"status":"ok","timestamp":1623063550522,"user_tz":-330,"elapsed":6,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"00527303-0e09-4e49-dc24-84fe123c8d59"},"source":["# load json and create model\n","json_file = open('output/model/model_pedestrian.json', 'r',encoding='utf-8-sig')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","from keras.models import model_from_json\n","model_pedestrian = model_from_json(loaded_model_json)\n","\n","# load weights into new model\n","model_pedestrian.load_weights(\"output/model/model_pedestrian.h5\")\n","print(\"Loaded model from disk\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded model from disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XHvlKOOoTAWILH5t3QnGSS0mGcZj_r08"},"id":"AkF_rZtfPyvY","executionInfo":{"status":"ok","timestamp":1623063611881,"user_tz":-330,"elapsed":61363,"user":{"displayName":"MARIA JAMES 55","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh0qlC-mixj7tLlTX3TGkWdHFE7MG2jqYzFEhui=s64","userId":"03735601092024387913"}},"outputId":"9c912a43-34cc-4430-c357-5e4cc71905c3"},"source":["pred_all_car= model_car.predict(val_img_car)\n","np.shape(pred_all_car)\n","\n","pred_all_pedestrian= model_pedestrian.predict(val_img_van)\n","np.shape(pred_all_pedestrian)\n","\n","\n","for i in range(64):\n","    print(\"Input: \",i)\n","    im = np.array(255*val_img_pedestrian[i],dtype=np.uint8)\n","    cv2_imshow(im)\n","\n","    print(\"Ground Truth\")\n","    #draw_mask_id(df_val_list[i])\n","    im_mask = np.array(255*val_mask_pedestrian[i],dtype=np.uint8)\n","    rgb_mask_true_pedestrian= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n","    rgb_mask_true_pedestrian[:,:,0] = 0*rgb_mask_true_pedestrian[:,:,0]\n","    rgb_mask_true_pedestrian[:,:,2] = 0*rgb_mask_true_pedestrian[:,:,2]\n","    #img_true_pedestrian = cv2.addWeighted(rgb_mask_true_pedestrian,0.5,im,0.5,0)\n","    #cv2_imshow(img_true)\n","    im_mask = np.array(255*val_mask_car[i],dtype=np.uint8)\n","    rgb_mask_true_car= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n","    rgb_mask_true_car[:,:,0] = 0*rgb_mask_true_car[:,:,0]\n","    rgb_mask_true_car[:,:,2] = 0*rgb_mask_true_car[:,:,2]\n","    \n","    img_true = cv2.addWeighted(rgb_mask_true_pedestrian,0.5,rgb_mask_true_car ,0.5,0)\n","\n","    img_true = cv2.addWeighted(img_true,0.5,im,0.5,0)\n","    cv2_imshow(img_true)\n","\n","\n","    im_pred = np.array(255*pred_all_pedestrian[i],dtype=np.uint8)\n","    #rgb_mask_box = cv2.cvtColor(rgb_mask_pred, cv2.COLOR_BGR2GRAY);\n","    from google.colab.patches import cv2_imshow\n","    rgb_mask_box= im_pred\n","    #cv2_imshow(rgb_mask_box)\n","    ret,thresh = cv2.threshold(rgb_mask_box,127,255,0)\n","    img2 = im\n","    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n","    cv2.drawContours(rgb_mask_box, contours, -1, (0,255,0), 3)\n","    #print(contours)\n","\n","    for c in contours:\n","        rect = cv2.boundingRect(c)\n","        #if rect[2] < 100 or rect[3] < 100: continue\n","        #print(cv2.contourArea(c))\n","        x,y,w,h = rect\n","        cv2.rectangle(img2,(x,y),(x+w,y+h),(255,0,0),3)\n","        cv2.putText(img2,'PEDESTRIAN',(x,y-2),0,0.3,(255,0,0))\n","    \n","\n","\n","    im_pred = np.array(255*pred_all_car[i],dtype=np.uint8)\n","    #rgb_mask_box = cv2.cvtColor(rgb_mask_pred, cv2.COLOR_BGR2GRAY);\n","    #from google.colab.patches import cv2_imshow\n","    rgb_mask_box= im_pred\n","    #cv2_imshow(rgb_mask_box)\n","    ret,thresh = cv2.threshold(rgb_mask_box,127,255,0)\n","    img3 = img2\n","    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n","    cv2.drawContours(rgb_mask_box, contours, -1, (0,255,0), 3)\n","    #print(contours)\n","\n","    for c in contours:\n","        rect = cv2.boundingRect(c)\n","        #if rect[2] < 100 or rect[3] < 100: continue\n","        #print(cv2.contourArea(c))\n","        x,y,w,h = rect\n","        cv2.rectangle(img3,(x,y),(x+w,y+h),(0,255,0),3)\n","        cv2.putText(img3,'CAR',(x,y-2),0,0.3,(0,255,0))\n","\n","\n","    \n","    print(\"Result\")\n","    cv2_imshow(img3)\n","    print(\"\\n\")\n","  "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"a1nj4WjNPkup"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqAljq_l7kY5"},"source":[""],"execution_count":null,"outputs":[]}]}